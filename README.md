# Overview
This repository contains 3 mini-projects:

## `Basic_CNN` sub-directory

Below is how the project is structured

```
ðŸ“¦Basic_CNN
 â”£ ðŸ“‚emnist
 â”ƒ â”£ ðŸ“œemnist-letters-test.csv      # must be obtained from Kaggle
 â”ƒ â”— ðŸ“œemnist-letters-train.csv     # must be obtained from Kaggle
 â”£ ðŸ“œLetter_Detection.ipynb
 â”£ ðŸ“œmacBookImage.ipynb
 â”— ðŸ“œmacbook_image.jpg
```

`Letter_Detection.ipynb` is a Python Notebook which contains a construction of a simple CNN (Convolutional Neural Network) model using Keras. This CNN model was trained with the [**EMNIST dataset obtained from kaggle**](https://www.kaggle.com/crawford/emnist?select=emnist-letters-train.csv), specifically the `emnist-letters-train.csv` and `emnist-letters-test.csv`. Please download these 2 CSV files from Kaggle and save them under `emnist` sub-directory. GitHub has a limit of uploading files larger than 100MB so I can't upload it to this repository

`macBookImage.ipynb` is a Python Notebook where I tried to test image thresholding and other image transformation with OpenCV library

## `everymac_spider_project` sub-directory

Contains `everymac_spider` which was used to scrape everymac for MacBook datasets. This spider is working quite well and it's able to convert MacBook related webpages on everymac to a CSV dataset. Below is how the project is structured:

```
ðŸ“¦everymac_spider_project
 â”£ ðŸ“‚everymac
 â”ƒ â”£ ðŸ“‚spiders
 â”ƒ â”ƒ â”£ ðŸ“œ__init__.py
 â”ƒ â”ƒ â”— ðŸ“œeverymac_spider.py
 â”ƒ â”£ ðŸ“œ__init__.py
 â”ƒ â”£ ðŸ“œitems.py
 â”ƒ â”£ ðŸ“œmiddlewares.py
 â”ƒ â”£ ðŸ“œpipelines.py
 â”ƒ â”£ ðŸ“œsettings.py
 â”ƒ â”— ðŸ“œtests.ipynb
 â”£ ðŸ“‚output_csv
 â”ƒ â”£ ðŸ“œmacbook.csv
 â”ƒ â”— ðŸ“œmacbook_pro.csv
 â”— ðŸ“œscrapy.cfg
 ```

`everymac_spider.py` Python module which defines the spider is inside the `spiders` sub-directory in this project

```
ðŸ“¦everymac_spider_project
 â”£ ðŸ“‚everymac
 â”ƒ â”£ ðŸ“‚spiders
 â”ƒ â”ƒ â”— ðŸ“œeverymac_spider.py
```

The 2 CSV output included in this repository as a result of running the spyder are located under `output_csv`

```
ðŸ“¦everymac_spider_project
 â”£ ðŸ“‚output_csv
 â”ƒ â”£ ðŸ“œmacbook.csv
 â”ƒ â”— ðŸ“œmacbook_pro.csv
```

## Image Text Extraction Proof of Concept (POC)

Essentially, this is the final Proof Of Concept (POC) made for the capstone project. The main file which contains all of the Python code is `text_extraction_poc.ipynb` Python Notebook. Here are the things which the Python notebook does:
- It read input images from `input_images` sub-directory 
- Did some image pre-processing on each input image and saved the final binary images under `output_bin_img` sub-directory
- Saved all text extracted from each pre-processed binary image (using Tesseract) into separate text files located under `text_extract` sub-directory.

This is how the project is structured:

```
ðŸ“¦ DATA6000_Capstone
 â”£ ðŸ“‚input_images
 â”ƒ â”£ ðŸ“œmacbook_box_image.jpeg
 â”ƒ â”£ ðŸ“œmacbook_image_1.jpeg
 â”ƒ â”£ ðŸ“œmacbook_image_2.jpg
 â”ƒ â”— ðŸ“œmacbook_image_3.jpeg
 â”£ ðŸ“‚output_bin_img
 â”ƒ â”£ ðŸ“œmacbook_box_image.jpg
 â”ƒ â”£ ðŸ“œmacbook_image_1.jpg
 â”ƒ â”£ ðŸ“œmacbook_image_2.jpg
 â”ƒ â”— ðŸ“œmacbook_image_3.jpg
 â”£ ðŸ“‚text_extract
 â”ƒ â”£ ðŸ“œmacbook_box_image.txt
 â”ƒ â”£ ðŸ“œmacbook_image_1.txt
 â”ƒ â”£ ðŸ“œmacbook_image_2.txt
 â”ƒ â”— ðŸ“œmacbook_image_3.txt
 â”— ðŸ“œtext_extraction_poc.ipynb
```

The project used the `macbook_pro.csv` output generated by `everymac_spider` in the previous section to assign the appropriate laptop model based on laptop specification extracted from input images. 

# Create virtual environment on your machine

The easiest way is to setup a virtual environment on your machine to run the everymac spider and Python Notebooks in this project is to use either `conda` or `mamba` package manager and then run either:
- `mamba env create -f environment.yaml` if you're using mamba package manager **(the recommended way)**
- `conda env create -f environment.yaml` if you're using conda package manager

The command above will create `DATA6000_Capstone` mamba/conda virtual environment on your machine. You can then activate the virtual environment with `conda activate DATA6000_Capstone`

---
**Change Virtual Env Name**

You can easily change the name of virtual environment created from the YAML file by giving conda/mamba the `--name` parameter value.

For instance, if you want the virtual environment to be named `some_env` with mamba package manager then just run `mamba env create -f environment.yaml --name some_env`

---

# Running the spider to scrape everymac Macbook Listings

In order to run the spider, navigate to the `everymac_spider_project` sub-directory and then run 

```
## the <csv_output_filename> below is up to the user to decide ##

scrapy crawl everymac_spider -o <csv_output_filename>.csv
``` 

You can see that there are 2 CSV outputs already available inside `output_csv` folder:
- `macbook_pro.csv` contains hardware spec details for all Apple MacBook Pro lineup ***(MacBook Pro 16", MacBook Pro 15", etc.)***
- `macbook.csv` contains hardware spec details for all Apple Macbooks ***(Macbook 12", Macbook, etc.)***

